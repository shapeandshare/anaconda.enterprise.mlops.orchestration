{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MLFlow Model Serving For Anaconda Enterprise\n",
    "This notebook is meant to provide an exmaple of how to use the endpoint project to deploy endpoints using model from the MLFlow Tracking Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Create an instance of an AE Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anaconda.enterprise.server.sdk.client import AEClient\n",
    "from src.utils import get_ae_client\n",
    "\n",
    "client: AEClient = get_ae_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Upload Endpoint Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from anaconda.enterprise.server.contracts import ProjectUploadResponse\n",
    "\n",
    "# Define the server template to upload\n",
    "SERVER_TEMPLATE_PATH: str = Path(\"../../assets/mlflow.model.serving.0.4.0.tar.gz\").resolve().as_posix()\n",
    "\n",
    "# Define the project name\n",
    "SERVER_PROJECT_NAME: str = \"dev.mlflow.endpoint.taxi\"\n",
    "\n",
    "upload_response: ProjectUploadResponse = client.project_upload(\n",
    "    project_archive_path=SERVER_TEMPLATE_PATH,\n",
    "    name=SERVER_PROJECT_NAME,\n",
    ")\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_revisions = client.project_revisions_get(project_id=upload_response.id)\n",
    "project_revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. Define the Deployment Options\n",
    "This will include specifying the registered model name and stage to load from the model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_SERVING_MODEL_NAME: str = \"taxi_fare_regressor\"\n",
    "MLFLOW_SERVING_MODEL_STAGE: str = \"Staging\"\n",
    "SERVER_DEPLOYMENT_NAME: str = \"dev.mlflow.endpoint.taxi.fare.regressor\"\n",
    "SERVER_DEPLOYMENT_STATIC_ENDPOINT: str = \"dev-mlflow-endpoint-taxi-fare-regressor\"\n",
    "\n",
    "deploy_params: dict = {\n",
    "    \"project_id\": upload_response.id,\n",
    "    \"deployment_name\": SERVER_DEPLOYMENT_NAME,\n",
    "    \"revision_id\": project_revisions[0].id,\n",
    "    \"command\": \"Serve\",\n",
    "    \"variables\": {\n",
    "        \"MLFLOW_SERVING_MODEL_NAME\": MLFLOW_SERVING_MODEL_NAME,\n",
    "        \"MLFLOW_SERVING_MODEL_STAGE\": MLFLOW_SERVING_MODEL_STAGE,\n",
    "    },\n",
    "    \"static_endpoint\": SERVER_DEPLOYMENT_STATIC_ENDPOINT,\n",
    "}\n",
    "deploy_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4. Deploy the Model Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anaconda.enterprise.server.contracts import ProjectDeployResponse\n",
    "\n",
    "project_deploy_response: ProjectDeployResponse = client.project_deploy(**deploy_params)\n",
    "project_deploy_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5. Generate Private Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token: str = client.deployment_token_get(deployment_id=project_deploy_response.id)\n",
    "access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6. Get Deployment URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint: str = project_deploy_response.url\n",
    "service_endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
