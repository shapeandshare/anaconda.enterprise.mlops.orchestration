{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Tracking Server For Anaconda Enterprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing an installation you should familiarize yourself with below topics:\n",
    "\n",
    "* [High Level Concepts](https://github.com/shapeandshare/mlflow.tracking.server/blob/main/docs/source/high_level_concepts.md)\n",
    "* [MLFlow Tracking Server Overview](https://github.com/shapeandshare/mlflow.tracking.server/blob/main/docs/source/server_overview.md)\n",
    "* [Installation Guide](https://github.com/shapeandshare/mlflow.tracking.server/blob/main/docs/source/installation_guide.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create an instance of an AE Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from anaconda.enterprise.server.sdk.client import AEClient\n",
    "from src.utils import get_ae_client\n",
    "\n",
    "client: AEClient = get_ae_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Populate our service account secrets used for configuration (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from anaconda.enterprise.server.common.sdk import demand_env_var\n",
    "\n",
    "# Define our secrets\n",
    "secret_names: list[str] = [\"MLFLOW_BACKEND_STORE_URI\", \"MLFLOW_ARTIFACTS_DESTINATION\", \"MLFLOW_TRACKING_GC_TTL\"]\n",
    "\n",
    "# Remove possibly pre-existing configurations\n",
    "for name in secret_names:\n",
    "    try:\n",
    "        client.secret_delete(key=name)\n",
    "    except Exception as error:\n",
    "        # This is broad to allow for catching and reporting everything.\n",
    "        print(error)\n",
    "\n",
    "    # [re]create the secrets using the latest values.\n",
    "    value: str = demand_env_var(name=name)\n",
    "    print(f\"{name}:{value}\")\n",
    "    client.secret_put(key=name, value=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Upload Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from anaconda.enterprise.server.contracts import ProjectUploadResponse\n",
    "\n",
    "# Define the server template to upload\n",
    "SERVER_TEMPLATE_PATH: str = Path(\"mlflow.tracking.server-0.5.12.tar.gz\").resolve().as_posix()\n",
    "\n",
    "# Define the project name\n",
    "SERVER_PROJECT_NAME: str = \"dev.mlflow.tracking.server\"\n",
    "\n",
    "upload_response: ProjectUploadResponse = client.project_upload(\n",
    "    project_archive_path=SERVER_TEMPLATE_PATH,\n",
    "    name=SERVER_PROJECT_NAME,\n",
    ")\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 (Disaster Recovery Steps)\n",
    "If performing a disaster recover then at this point the data can be restored to database and filesystem before moving to step 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Get project revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "project_revisions = client.project_revisions_get(project_id=upload_response.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Define the Deployment Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_DEPLOYMENT_NAME: str = \"dev-mlflow-tracking-server\"\n",
    "SERVER_DEPLOYMENT_STATIC_ENDPOINT: str = \"dev-mlflow-tracking-server\"\n",
    "\n",
    "deploy_params: dict = {\n",
    "    \"project_id\": upload_response.id,\n",
    "    \"deployment_name\": SERVER_DEPLOYMENT_NAME,\n",
    "    \"revision_id\": project_revisions[0].id,\n",
    "    \"command\": project_revisions[0].commands[0].id,\n",
    "    \"variables\": {\n",
    "        \"MLFLOW_BACKEND_STORE_URI\": demand_env_var(name=\"MLFLOW_BACKEND_STORE_URI\"),\n",
    "        \"MLFLOW_ARTIFACTS_DESTINATION\": demand_env_var(name=\"MLFLOW_ARTIFACTS_DESTINATION\"),\n",
    "        \"MLFLOW_TRACKING_GC_TTL\": demand_env_var(name=\"MLFLOW_TRACKING_GC_TTL\"),\n",
    "    },\n",
    "    \"static_endpoint\": SERVER_DEPLOYMENT_STATIC_ENDPOINT,\n",
    "}\n",
    "deploy_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deploy the MLFlow Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anaconda.enterprise.server.contracts import ProjectDeployResponse\n",
    "\n",
    "project_deploy_response: ProjectDeployResponse = client.project_deploy(**deploy_params)\n",
    "project_deploy_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Generate Private Access Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token: str = client.deployment_token_get(deployment_id=project_deploy_response.id)\n",
    "access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Get Deployment URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint: str = project_deploy_response.url\n",
    "service_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Populate our service account secrets used for configuration (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our secrets\n",
    "secrets: dict[str, str] = {\n",
    "    \"MLFLOW_TRACKING_URI\": service_endpoint,\n",
    "    \"MLFLOW_REGISTRY_URI\": service_endpoint,\n",
    "    \"MLFLOW_TRACKING_TOKEN\": access_token,\n",
    "}\n",
    "\n",
    "print(\"The below values MUST bew provided to clients who wish to access the server and it's API.\")\n",
    "print(\n",
    "    \"Please note that since this is a private deployment that a new token MUST be provided each time the server is restarted.\"\n",
    ")\n",
    "\n",
    "# [Re]create the secrets using the latest values.\n",
    "for key, value in secrets.items():\n",
    "    print(f\"{key}:{value}\")\n",
    "    client.secret_delete(key=key)\n",
    "    client.secret_put(key=key, value=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create the Garbage Collection Schedule\n",
    "\n",
    "It is recommended to create a garbage collection schedule.  To do so use the ae5 tools.  The below will generate an ae5 command suitable for creating a basic schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_creation_command: str = f\"ae5 job create --command 'GarbageCollection' --schedule '*/10 * * * *' --name 'Scheduled {SERVER_PROJECT_NAME} Garbage Collection' '{SERVER_PROJECT_NAME}'\"\n",
    "job_creation_command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
